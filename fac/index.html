
<!doctype html>
<html lang="en">

<head>
  <meta name="google-site-verification" content="ftFOlJETX-2KNjaPh8W6s8lhigItRuu9fOmjHZZ0nY0" />
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css"
    integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">

  <title>Towards Fine-Grained Prosody Control for Voice Conversion</title>
</head>
<style type="text/css">
  table {
    width: 100%;
    table-layout: fixed;
  }

  audio {
    width: 100%;
  }

  thead>tr>th:first-child {
    width: 96px;
  }

  @media (max-width: 767px) {
    .big-screen {
      display: none;
    }
  }

  @media (min-width: 767px) {
    .small-screen {
      display: none;
    }
  }
</style>

<body>
  <header class="header">
    <div class="jumbotron bg-secondary text-center">
      <div class="container">
        <div class="row align-items-center">
          <div class="col-md-12">
            <h1><a class="text-light">
				 Foreign Accent Conversion Using Reference Encoder<br> (Submitted to Interspeech2020)</a></h1>
            <p>
              <div class="row">
                <div class="col-md col-sm-12"><a class="text-light">Wenjie Li Benlai Tang</a> </div>
              </div>
            </p>
			<p><a class="text-light"> Xinjiang University,Urumqi, China<br>
				</p></a>
				
          </div>
        </div>
      </div>
    </div>
  </header>
  <main>
    <div class="container">
      <div class="row" id="intro">
        <div class="col">
          <h2>Notes</h2>
          <div>
            <p> ZHAA's native language is Arabic</p>
	    <p>	Dataset (L2-ARCTIC corpus) <a class="text-success" href="#1">[1]</a>: https://psi.engr.tamu.edu/l2-arctic-corpus</p>
	    <p>	Please view this page in Google Chrome or Microsoft Edge for best quality</p>
          </div>
        </div>
      </div>
      <hr>
      <div class="row" id="monolingual">
        <div class="col">
          <h2>System</h2>
          <div>
		<p>baseline [2]:https://github.com/guanlongzhao/fac-via-ppg</p>
		<p>proposed system1:CBHG encoder+GMM Attention</p>
		<p>proposed system2:mel reference encoder + CBHG encoder+GMM Attention</p>
		<p>proposed system3:mel and phone sequence reference encoder+CBHG encoder+GMM Attention</p>
		<br>
          </div>
        </div>
      </div>

      <hr>
      <div class="row" id="result">
        <div class="col-md-12">
          <h2>Speech Samples</h2>
          <p>Using ZHAA as source accent:
          <br>
          Using tts generate audio as target accent.
		  </p>
		  
                  <div class="big-screen">
                    <table class="table">
                      <thead>
                        <tr>
                          <th></th>
                          <th>ZHAA</th>
                          <th>Baseline</th>
			  <th>proposed system1</th>
			  <th>proposed system2</th>
			  <th>proposed system3</th>

                        </tr>
                      </thead>
                      <tbody>
						
						<tr>
                          <th scope="row">Sample 1</th>
                          <td>
                            <audio controls>
                              <source src="https://raw.githubusercontent.com/kal009l/kal009l.github.io/master/demo/zhaa/000002_.npy.wav" type="audio/wav" />
                            </audio>
                          </td>
                          <td>
                            <audio controls>
                              <source src="https://raw.githubusercontent.com/kal009l/kal009l.github.io/master/demo/baseline/000002_.npy.wav" type="audio/wav" />
                            </audio>
                          </td>
                          <td>
                            <audio controls>
                              <source src="https://raw.githubusercontent.com/kal009l/kal009l.github.io/master/demo/cbhg/000002_.npy.wav" type="audio/wav" />
                            </audio>
                          </td>
						  <td>
                            <audio controls>
                              <source src="https://raw.githubusercontent.com/kal009l/kal009l.github.io/master/demo/mel_refer/000002_.npy.wav" type="audio/wav" />
                            </audio>
                          </td>
                          <td>
                            <audio controls>
                              <source src="https://raw.githubusercontent.com/kal009l/kal009l.github.io/master/demo/mel_text_refer/000002_.npy.wav" type="audio/wav" />
                            </audio>
                          </td>
                        </tr>
						
						
						
						
			<tr>
                          <th scope="row">Sample 2</th>
                          <td>
                            <audio controls>
                              <source src="https://raw.githubusercontent.com/kal009l/kal009l.github.io/master/demo/zhaa/000025_.npy.wav" type="audio/wav" />
                            </audio>
                          </td>
                          <td>
                            <audio controls>
                              <source src="https://raw.githubusercontent.com/kal009l/kal009l.github.io/master/demo/baseline/000025_.npy.wav" type="audio/wav" />
                            </audio>
                          </td>
                          <td>
                            <audio controls>
                              <source src="https://raw.githubusercontent.com/kal009l/kal009l.github.io/master/demo/cbhg/000025_.npy.wav" type="audio/wav" />
                            </audio>
                          </td>
			  <td>
                            <audio controls>
                              <source src="https://raw.githubusercontent.com/kal009l/kal009l.github.io/master/demo/mel_refer/000025_.npy.wav" type="audio/wav" />
                            </audio>
                          </td>
                          <td>
                            <audio controls>
                              <source src="https://raw.githubusercontent.com/kal009l/kal009l.github.io/master/demo/mel_text_refer/000025_.npy.wav" type="audio/wav" />
                            </audio>
                          </td>
                        </tr>
						
						
						
			<tr>
                          <th scope="row">Sample 3</th>
                          <td>
                            <audio controls>
                              <source src="https://raw.githubusercontent.com/kal009l/kal009l.github.io/master/demo/zhaa/000046_.npy.wav" type="audio/wav" />
                            </audio>
                          </td>
                          <td>
                            <audio controls>
                              <source src="https://raw.githubusercontent.com/kal009l/kal009l.github.io/master/demo/baseline/000046_.npy.wav" type="audio/wav" />
                            </audio>
                          </td>
						  
                          <td>
                            <audio controls>
                              <source src="https://raw.githubusercontent.com/kal009l/kal009l.github.io/master/demo/cbhg/000046_.npy.wav" type="audio/wav" />
                            </audio>
                          </td>
						  <td>
                            <audio controls>
                              <source src="https://raw.githubusercontent.com/kal009l/kal009l.github.io/master/demo/mel_refer/000046_.npy.wav" type="audio/wav" />
                            </audio>
                          </td>
                          <td>
                            <audio controls>
                              <source src="https://raw.githubusercontent.com/kal009l/kal009l.github.io/master/demo/mel_text_refer/000046_.npy.wav" type="audio/wav" />
                            </audio>
				</td>
                        </tr>
						
						
						
						
						<tr>
                          <th scope="row">Sample 4</th>
                          <td>
                            <audio controls>
                              <source src="https://raw.githubusercontent.com/kal009l/kal009l.github.io/master/demo/zhaa/000058_.npy.wav" type="audio/wav" />
                            </audio>
                          </td>
                          <td>
                            <audio controls>
                              <source src="https://raw.githubusercontent.com/kal009l/kal009l.github.io/master/demo/baseline/000058_.npy.wav" type="audio/wav" />
                            </audio>
                          </td>
						  
                          <td>
                            <audio controls>
                              <source src="https://raw.githubusercontent.com/kal009l/kal009l.github.io/master/demo/cbhg/000058_.npy.wav" type="audio/wav" />
                            </audio>
                          </td>
						  <td>
                            <audio controls>
                              <source src="https://raw.githubusercontent.com/kal009l/kal009l.github.io/master/demo/mel_refer/000058_.npy.wav" type="audio/wav" />
                            </audio>
                          </td>
                          <td>
                            <audio controls>
                              <source src="https://raw.githubusercontent.com/kal009l/kal009l.github.io/master/demo/mel_text_refer/000058_.npy.wav" type="audio/wav" />
                            </audio>
                          </td>
			      </tr>	
                  </div>
      <hr>		  		  
      <div class="row" id="ref">
        <div class="col">
          <h2>References</h2>
          <div>
            <p>
              <a name="1">[1]</a>
              Lifa Sun, Hao Wang, Shiyin Kang, Kun Li and Helen Meng, <a class="text-success"
                href="http://www1.se.cuhk.edu.hk/~hccl/publications/pub/2016_IS16_SunLifa.PDF">“Personalized,
                Cross-lingual TTS Using Phonetic Posteriorgrams</a>,” in <em>INTERSPEECH, 2016, pp. 322-326.</em>
            </p>
            <p>
              <a name="2">[2]</a>
              Valin Jean-Marc and Skoglund Jan, <a class="text-success"
                href="https://jmvalin.ca/papers/lpcnet_icassp2019.pdf">“LPCNet: Improving neural speech 
                synthesis through linear prediction</a>,” in <em>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)
                , 2019, pp. 5891–5895.</em>
            </p>
            <p>
              <a name="3">[3]</a>
              Skerry-Ryan RJ, Battenberg Eric, Xiao Ying, Wang Yuxuan, Stanton Daisy, Shor Joel, Weiss Ron J, Clark Rob and Saurous Rif A, 
              <a class="text-success" href="https://arxiv.org/pdf/1803.09047.pdf">“Towards end-to-end prosody transfer for expressive speech
              synthesis with tacotron</a>,” in <em>arXiv, 2018.</em>
            </p>
          </div>
        </div>
      </div>
      <hr>
      <!-- <div class="row" id="contact">
          <div class="col">
            <h2>Contact</h2>
            <div></div>
          </div>
        </div> -->
    </div>
  </main>
  <footer class="bg-secondary text-light mt-4 pt-3 pb-2 ">
    <div class="container">
      <p class="text-center">
        <small>
          Towards Fine-Grained Prosody Control for Voice Conversion
          <br>
          <a class="text-light"><strong>Zheng Lian</strong></a> |
          lianzheng2016@ia.ac.cn
        </small>
      </p>
    </div>
  </footer>
  <!-- Optional JavaScript -->
  <!-- jQuery first, then Popper.js, then Bootstrap JS -->
  <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"
    integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo"
    crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js"
    integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49"
    crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js"
    integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy"
    crossorigin="anonymous"></script>
</body>

</html>
